cdef class CTRNN:
    cdef int N
    cdef double step_size, sigma
    cdef double[:] Y, dy_dt, I, Tau, Theta, G
    cdef double[:, :] W
    cdef object tau_range, g_range, theta_range, w_range

cdef double[:] center_cross(double[:,:] weights)
cdef double[:] sigmoid(double[:] x)
cdef dot(double[:, :] A, double[:] B)





import numpy as np
cimport numpy as np
from math import exp
from cpython cimport array as cvarray


cdef class CTRNN:

    def __cinit__(self, int number_of_neurons, double step_size, object tau_range,
                  object gain_range, object theta_range, object w_range):
        """
        Initialize a fully connected CTRNN of size N (number_of_neurons) with the following attributes:
        Y      = 'state of each neuron' at current time point i
        Tau    = 'time constant (tau > 0)'
        W     = 'fixed strength of the connection from jth to ith neuron', Weight Matrix
        Theta = 'the bias term'
        sigma = 'the sigmoid function / standard logistic activation function' 1/(1+np.exp(-x))
        I     = 'constant external input' at current time point i
        G     = 'gain' (makes neurons highly sensitive to their input, primarily for motor or sensory nodes)
                 Preferably g is between [1,5] and just > 1 for neurons connected to sensory input or motor output.
        :param number_of_neurons: number of neurons in the network
        :param step_size: step size for the update function
        :param tau: time constants
        :param gain: gains
        :param theta: bias terms
        :param weights: weights
        :return: output
        """

        self.step_size = step_size
        self.N = number_of_neurons
        self.Y = cvarray(shape=(1, self.N))
        self.dy_dt = cvarray(shape=(1, self.N))
        self.I = cvarray(shape=(1, self.N))
        self.tau_range = tau_range
        self.g_range = gain_range
        self.theta_range = theta_range
        self.w_range = w_range
        # In the random searches, the initial population is generated by randomly assigning parameter values drawn from
        # a uniform distribution over the allowed ranges
        self.Tau = np.random.uniform(self.tau_range[0], self.tau_range[1], self.N)
        self.G = np.random.uniform(self.g_range[0], self.g_range[1], self.N)
        self.W = np.random.uniform(self.w_range[0], self.w_range[1], (self.N, self.N))
        # self.Theta = np.random.uniform(self.theta_range[0], self.theta_range[1], self.N)
        self.Theta = center_cross(self.W)
        # self.genotype = self.make_genotype_from_params()  # these are the evolvable parameters

    def randomize_state(self, state_range):
        # To start the simulation it is often useful to randomize initial neuron activation around 0
        self.Y = np.random.uniform(state_range[0], state_range[1], self.N)

    def euler_step(self):
        #for i in range(100000):
        # Compute the next state of the network given its current state and the simple euler equation
        # update the outputs of all neurons
        cdef int i
        cdef int num = self.Y.shape[0]
        cdef double[:] mult = cvarray(shape=(1, num))
        cdef double[:] o = cvarray(shape=(1, num))

        for i in range(num):
            mult[i] = self.G[i] * (self.Y[i] + self.Theta[::i])
        o = sigmoid(mult)
        # update the state of all neurons
        for i in range(num):
            self.dy_dt[i] = self.step_size * 1/self.Tau[i] * (-self.Y[i] + self.I[i]) * dot(self.W, o)
            self.Y[i] = self.Y[i] + self.dy_dt[i]

    def get_state(self):
        return self.Y


cdef double[:] center_cross(double[:, :] weights):
    cdef:
        size_t rows_x, cols_x
        size_t i, j
        double[:] theta
    rows_x, cols_x = weights.shape[0], weights.shape[1]
    theta = cvarray(shape=(1, rows_x))
    for i in range(rows_x):
        s = 0
        for j in range(cols_x):
            s += weights[i, j]
        theta[i] = -s/2
    return theta

cdef double[:] sigmoid(double[:] x):
    cdef:
        size_t rows_x
        size_t i
        double[:] out
    rows_x = x.shape[0]
    out = cvarray(shape=(1, rows_x))
    for i in range(rows_x):
        out[i] = 1 / (1 + exp(-x[i]))
    return out


cdef dot(double[:, :] A, double[:] B):
    cdef:
        size_t rows_A, cols_A, rows_B, cols_B
        size_t i, j, k
        double s
        double[:] out
    rows_A, cols_A = A.shape[0], A.shape[1]
    rows_B = B.shape[0]
    out = cvarray(shape=(1, rows_A))
    # Take each row in A
    for i in range(rows_A):
        # And multiply by every column in B
        s = 0
        for j in range(rows_B):
            s = s + A[i, j] * B[j]
        out[i] = s
    return out